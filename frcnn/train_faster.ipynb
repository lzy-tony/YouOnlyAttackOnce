{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readline import remove_history_item\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torchvision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from utils.config import opt\n",
    "from model import FasterRCNNVGG16\n",
    "from trainer import FasterRCNNTrainer\n",
    "from data.util import  read_image\n",
    "from utils.vis_tool import vis_bbox, vis_image\n",
    "from utils import array_tool as at\n",
    "\n",
    "def getBack(var_grad_fn):\n",
    "    print(var_grad_fn)\n",
    "    for n in var_grad_fn.next_functions:\n",
    "        if n[0]:\n",
    "            try:\n",
    "                tensor = getattr(n[0], 'variable')\n",
    "                print(n[0])\n",
    "                print('Tensor with grad found:', tensor.shape)\n",
    "                print(' - gradient:', tensor.grad.shape)\n",
    "                print()\n",
    "            except AttributeError as e:\n",
    "                getBack(n[0])\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "num = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "input_path = \"/home/duanchengqi20/Patch/image/1_223.jpg\"\n",
    "# model = torch.hub.load('/home/duanchengqi20/.cache/torch/hub/ultralytics_yolov3_master', 'yolov3', source=\"local\").to(device)  # or yolov3-spp, yolov3-tiny, custom\n",
    "# model.eval()\n",
    "faster_rcnn = FasterRCNNVGG16()\n",
    "trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "trainer.load('/home/duanchengqi20/Patch/simple-faster-rcnn/chainer_best_model_converted_to_pytorch_0.7053.pth')\n",
    "\n",
    "with open(\"/home/duanchengqi20/Patch/loc.json\", \"r\") as f:\n",
    "    loc = json.load(f)\n",
    "\n",
    "train_img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data\n",
    "        self.len = len(data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x[item].cnt\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def patch_init():\n",
    "    a = np.random.randint(255, size=(1080, 1920, 3))\n",
    "    a = torch.autograd.Variable(torch.from_numpy(a).type(torch.float32), True)\n",
    "    return a.to(device)\n",
    "\n",
    "cnt = 0 \n",
    "\n",
    "class img():\n",
    "    def __init__(self, path, name, cnt):\n",
    "        self.image = Image.open(path)\n",
    "        self.arr = np.array(self.image)\n",
    "        # img_to_tensor = transforms.ToTensor()\n",
    "        # pic = Image.open(path)\n",
    "        # self.tensor = img_to_tensor(pic)\n",
    "        # self.tensor = self.tensor.transpose(0,1).transpose(1,2).to(device)\n",
    "        self.tensor = torch.from_numpy(self.arr).type(torch.float32).to(device)\n",
    "        self.name = name\n",
    "        self.loc = loc[self.name]\n",
    "        self.shape = self.arr.shape\n",
    "        self.cnt = cnt\n",
    "\n",
    "    def init_patch(self):\n",
    "        bg = torch.zeros(self.shape).to(torch.float32)\n",
    "        a = np.random.randint(255, size=(self.loc[3], self.loc[2], 3))\n",
    "        a = torch.from_numpy(a).type(torch.float32)\n",
    "        bg[self.loc[1]:self.loc[1]+self.loc[3] , self.loc[0]:self.loc[0]+self.loc[2] , :] = a\n",
    "        return bg\n",
    "\n",
    "    def transform_patch(self, patch):\n",
    "        patch = patch.transpose(2,1).transpose(0,1)\n",
    "        img_reshaper = torch.nn.AdaptiveAvgPool2d((self.loc[3], self.loc[2])).to(device)\n",
    "        reshaped_patch = img_reshaper(patch)\n",
    "        reshaped_patch1 = F.pad(reshaped_patch,[self.loc[0],self.shape[1]-self.loc[0]-self.loc[2],self.loc[1],self.shape[0]-self.loc[1]-self.loc[3]])\n",
    "        reshaped_patch2 = reshaped_patch1.transpose(0,1).transpose(1,2)\n",
    "        # getBack(reshaped_patch.grad_fn)\n",
    "        return reshaped_patch2\n",
    "\n",
    "    def add_patch(self, patch):\n",
    "        patch = patch.to(device)\n",
    "        mask = torch.ones(self.shape)\n",
    "        mask[self.loc[1]:self.loc[1]+self.loc[3] , self.loc[0]:self.loc[0]+self.loc[2] , :] = 0\n",
    "        mask = mask.to(device)\n",
    "        return self.tensor * mask + patch * (1 - mask)\n",
    "\n",
    "\n",
    "    def save_img(self, adv, name):\n",
    "        adv = adv.squeeze(0)\n",
    "        if adv.shape[0] != 3:\n",
    "            adv = adv.transpose(2,1).transpose(1,0)\n",
    "        adv = (adv + 0.5).detach().cpu().numpy().transpose(1,2,0).astype(\"uint8\")\n",
    "        # toPIL = transforms.ToPILImage()\n",
    "        # pic = toPIL(adv)\n",
    "        # pic.save('/home/duanchengqi20/Patch/image/trained/test{}.png'.format(name))\n",
    "        Image.fromarray(adv).save('/home/duanchengqi20/Patch/image/trained/test{}.png'.format(name))\n",
    "\n",
    "\n",
    "    def attack(self, patch):\n",
    "        global cnt\n",
    "        # mask = torch.ones(self.shape)\n",
    "        # mask[self.loc[1]:self.loc[1]+self.loc[3] , self.loc[0]:self.loc[0]+self.loc[2] , :] = 0\n",
    "        # mask = mask.to(device)\n",
    "        # adv_x = (self.tensor * mask + patch * (1 - mask)).transpose(1,2).transpose(0,1).unsqueeze(0).to(torch.float32) / 255\n",
    "        adv_x = self.add_patch(patch).transpose(2,1).transpose(1,0).unsqueeze(0).to(torch.float32)\n",
    "        # adv_x = self.add_patch(patch).transpose(1,2).transpose(0,1).unsqueeze(0).to(torch.float32) / 255\n",
    "        self.save_img(adv_x, cnt)\n",
    "        cnt += 1\n",
    "        return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def los(files, _bboxes, _labels, _scores):\n",
    "    l = 0\n",
    "    for i, labels in enumerate(_labels):\n",
    "        vis_bbox(at.tonumpy(files[i].squeeze(0)),\n",
    "            at.tonumpy(_bboxes[i]),\n",
    "            at.tonumpy(_labels[i]).reshape(-1),\n",
    "            at.tonumpy(_scores[i]).reshape(-1))\n",
    "        for j, label in enumerate(labels):\n",
    "            if label == 5 or label == 6:\n",
    "                l += _scores[i][j]\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/home/duanchengqi20/Patch/image/raw\"\n",
    "files = os.listdir(input_path)\n",
    "for i, file in enumerate(files):\n",
    "    if i > 16:\n",
    "        continue\n",
    "    if file not in loc.keys():\n",
    "        continue\n",
    "    # if i > 0:\n",
    "    #     break\n",
    "    train_img.append(img(os.path.join(input_path, file), file, num))\n",
    "    num += 1\n",
    "\n",
    "train_set = mydataset(train_img)\n",
    "origin_patch = patch_init()\n",
    "origin_patch.retain_grad()\n",
    "batch_size = 4\n",
    "\n",
    "train_data_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "num_epoch = 1\n",
    "reshaped_patch = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:0 HAS STARTED\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    total = 0\n",
    "    print(\"EPOCH:{} HAS STARTED\".format(epoch))\n",
    "    for x in train_data_loader:\n",
    "        a = time.time()\n",
    "        x = [train_img[i] for i in x]\n",
    "        reshaped_patch.clear()\n",
    "        loss_list.clear()\n",
    "        reshaped_patch = [i.transform_patch(origin_patch) for i in x]\n",
    "        loss_list = [i.attack(reshaped_patch[t]) for t, i in enumerate(x)]\n",
    "        aaa = torch.concat(loss_list, 0)\n",
    "        # faster_rcnn.train()\n",
    "        _bboxes, _labels, _scores = trainer.faster_rcnn.predict(aaa, visualize=True)\n",
    "        # faster_rcnn.eval()\n",
    "        b = time.time()\n",
    "        total_loss = los(loss_list, _bboxes, _labels, _scores)\n",
    "        total += total_loss\n",
    "        c = time.time()\n",
    "        if total_loss == 0:\n",
    "            continue\n",
    "        total_loss = total_loss / batch_size\n",
    "        total_loss.backward()\n",
    "        # getBack(loss_list[0][1].grad_fn)\n",
    "        #print(origin_patch.grad)\n",
    "        origin_patch -= origin_patch.grad * (1e6 + 10*(1-epoch/1.5*num_epoch)*0.5/float(abs(origin_patch.grad).max()))\n",
    "        origin_patch.clamp(0, 255)\n",
    "        print(total_loss)\n",
    "        print(b-a, c-b)\n",
    "    if total / 60 < 1 or epoch == num_epoch - 1:\n",
    "        train_img[0].save_img(origin_patch, 100909)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ba2d7bd3d6d9cbd5d1b4ff306b32e2159abb902680c0da4b46f18fe6e4a0c73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
